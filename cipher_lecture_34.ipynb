{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFboEpM3tixZOl0aSqr9Ti",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vidushi2601/CipherSchools-DataSci-ML-Hybrid/blob/main/cipher_lecture_34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "#Load the Dataset\n",
        "data=pd.read_csv('chatbot_dataset.csv')\n",
        "\n",
        "#Preprocess the data\n",
        "nltk.download('punkt')\n",
        "data['Question']=data['Question'].apply(lambda x: ' '.join(nltk.word_tokenize(x.lower())))\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLTJP7AsdJqu",
        "outputId": "21fc2fb0-e642-42e0-82c6-b6fa5f1ea68a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Question  \\\n",
            "0                   introduction to the course   \n",
            "1  overview of data science and its importance   \n",
            "2    introduction to the data science workflow   \n",
            "3         key skills and tools in data science   \n",
            "4          where can i find my course videos ?   \n",
            "\n",
            "                                              Answer  \n",
            "0  Welcome to the data science course. Here you w...  \n",
            "1  Data science is crucial for making informed de...  \n",
            "2  The data science workflow includes data collec...  \n",
            "3  Important skills include programming, statisti...  \n",
            "4  You can find all your course videos on the Cip...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing Data"
      ],
      "metadata": {
        "id": "n7vKPf8Yes-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer=TfidfVectorizer()\n",
        "x=vectorizer.fit_transform(data['Question'])\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDzt51biernW",
        "outputId": "2ad0e1eb-6c41-4271-8f9b-4c8b80753fbd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48, 112)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a Text Classification Model"
      ],
      "metadata": {
        "id": "uWBJUCrwfKrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Split the data into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['Question'], data['Answer'], test_size=0.2, random_state=42)\n",
        "\n",
        "#create a model pipeline\n",
        "model=make_pipeline(TfidfVectorizer(),MultinomialNB())\n",
        "\n",
        "#Train the model\n",
        "model.fit(x_train, y_train)\n",
        "print(\"Model Training Complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2KjRZJEfX7U",
        "outputId": "148587b8-2fa3-4896-e290-9587cb8fe75e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Training Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing a Function to get Chatbot Responses"
      ],
      "metadata": {
        "id": "NZAbStIKhAqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to get a response from the chatbot\n",
        "def get_response(question):\n",
        "  question=' '.join(nltk.word_tokenize(question.lower()))\n",
        "  answer=model.predict([question])[0]\n",
        "  return answer\n",
        "\n",
        "#Testing the function\n",
        "print(get_response(\"What is NLP?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm-EDTZfhAMf",
        "outputId": "b4692da9-097d-4de1-8e18-bb1fc61b7997"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seaborn is a Python visualization library based on Matplotlib that provides a high-level interface for drawing attractive statistical graphics. This is covered in the Introduction to Matplotlib and Seaborn module.\n"
          ]
        }
      ]
    }
  ]
}